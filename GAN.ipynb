{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF92Hyj7CihRkfg2Qsp2Ex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VKR2004/3-2-2025/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wymiT_tnL3fr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, LeakyReLU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import initializers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10)\n",
        "random_dim=100"
      ],
      "metadata": {
        "id": "MBYXKJ_WPRnX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_minst_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    return (x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "pjtmZjtTPxGJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator(optimizer):\n",
        "    generator = Sequential()\n",
        "    generator.add(Dense(256, input_dim=random_dim, \\\n",
        "            kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    generator.add(Dense(512))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    generator.add(Dense(1024))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    generator.add(Dense(784, activation='tanh'))\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return generator"
      ],
      "metadata": {
        "id": "nGP2Q0kqP8Es"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator(optimizer):\n",
        "    discriminator = Sequential()\n",
        "    discriminator.add(Dense(1024, input_dim=784, \\\n",
        "                kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "    discriminator.add(Dense(512))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "    discriminator.add(Dense(256))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "    discriminator.add(Dense(1, activation='sigmoid'))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return discriminator"
      ],
      "metadata": {
        "id": "o3so1GfvQHrW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
        "\n",
        "    # We initially set trainable to False since we only want to train either the\n",
        "    # generator or discriminator at a time\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    # gan input (noise) will be 100-dimensional vectors\n",
        "    gan_input = Input(shape=(random_dim,))\n",
        "\n",
        "    # the output of the generator (an image)\n",
        "    x = generator(gan_input)\n",
        "\n",
        "    # get the output of the discriminator (probability if the image is real or not)\n",
        "    gan_output = discriminator(x)\n",
        "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    return gan"
      ],
      "metadata": {
        "id": "TbSk1NuqQS_d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), \\\n",
        "                          figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', \\\n",
        "                   cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "7XCXL4WTQhNZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs=1, batch_size=128):\n",
        "\n",
        "    #1 Get the training and testing data\n",
        "\n",
        "    x_train, y_train, x_test, y_test = load_minst_data()\n",
        "\n",
        "    # Split the training data into batches of size 128\n",
        "\n",
        "    batch_count = x_train.shape[0] / batch_size\n",
        "\n",
        "    #2. Build our GAN netowrk\n",
        "\n",
        "    adam = get_optimizer()\n",
        "\n",
        "    generator = get_generator(adam)\n",
        "\n",
        "    discriminator = get_discriminator(adam)\n",
        "\n",
        "    gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
        "\n",
        "\n",
        "    # 3\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "\n",
        "        print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "\n",
        "        for _ in tqdm(range(int(batch_count))):\n",
        "\n",
        "            # 4. Get a random set of input noise and images\n",
        "\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "\n",
        "            image_batch = x_train[np.random.randint(0, x_train.shape[0], \\\n",
        "\n",
        "                                                    size=batch_size)]\n",
        "\n",
        "            # 5. Generate fake MNIST images\n",
        "\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            X = np.concatenate([image_batch, generated_images])\n",
        "\n",
        "            # 6. Labels for generated and real data\n",
        "\n",
        "            y_dis = np.zeros(2*batch_size)\n",
        "\n",
        "            # One-sided label smoothing\n",
        "\n",
        "            y_dis[:batch_size] = 0.9\n",
        "\n",
        "#7. Train discriminator\n",
        "\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            discriminator.train_on_batch(X, y_dis)\n",
        "\n",
        "            #8. Train generator\n",
        "\n",
        "            noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "\n",
        "            y_gen = np.ones(batch_size)\n",
        "\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "        if e == 1 or e % 20 == 0:\n",
        "\n",
        "            plot_generated_images(e, generator)\n",
        "\n",
        "train(20, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "5TDNjyntQ6Dw",
        "outputId": "23556d74-73d3-499f-ecb0-3d0bc3b25916"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- Epoch 1 ---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/468 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/468 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0a50807de5fa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mplot_generated_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-0a50807de5fa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# 6. Labels for generated and real data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4G3IgFXMUdOQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1z1tyR1AUmMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}